1.2 case study tweet visualization 
mapd 
using GPU to paralell computations. 

Brute Force /massive parallelism 
- mapD (hadoop, and many others) 

Partitioning 
- split the data, operate on the part you need.
,vertical split, horizontal split 

sampling
- operate on the subset of data

summarization(core set, sketches)
-operate on a summary of the data. 


Data cleaning and collection

1.traditional ETL is too hard to integrate many sources. 
2. cleaning will be a big issue forever. 

hard to search code that you need to prevent you from redo. 


Data Wrangler
Data tamer


